{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i0ojRYtd4NBX",
        "outputId": "410a274b-80da-4aef-fc14-31e9286ff777"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "nvcc: NVIDIA (R) Cuda compiler driver\n",
            "Copyright (c) 2005-2023 NVIDIA Corporation\n",
            "Built on Tue_Aug_15_22:02:13_PDT_2023\n",
            "Cuda compilation tools, release 12.2, V12.2.140\n",
            "Build cuda_12.2.r12.2/compiler.33191640_0\n"
          ]
        }
      ],
      "source": [
        "!nvcc --version"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/andreinechaev/nvcc4jupyter.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0Fk0d7Of4Zw7",
        "outputId": "47ea0bac-ea61-4e35-910a-79da2b28c6bd"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/andreinechaev/nvcc4jupyter.git\n",
            "  Cloning https://github.com/andreinechaev/nvcc4jupyter.git to /tmp/pip-req-build-yr_x9ei2\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/andreinechaev/nvcc4jupyter.git /tmp/pip-req-build-yr_x9ei2\n",
            "  Resolved https://github.com/andreinechaev/nvcc4jupyter.git to commit 5741c522547756ac4bb7a16df32106a15efb8a57\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: nvcc4jupyter\n",
            "  Building wheel for nvcc4jupyter (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for nvcc4jupyter: filename=nvcc4jupyter-1.2.1-py3-none-any.whl size=10741 sha256=1c43b610d84440f376c57bb0b3d20f87e2433fdb6f06eb98d5fd7c81c461a971\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-tgldax6l/wheels/a8/b9/18/23f8ef71ceb0f63297dd1903aedd067e6243a68ea756d6feea\n",
            "Successfully built nvcc4jupyter\n",
            "Installing collected packages: nvcc4jupyter\n",
            "Successfully installed nvcc4jupyter-1.2.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%load_ext nvcc4jupyter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t7ubqw2h4iS3",
        "outputId": "25078d54-df10-401a-e636-cf4ea27b97e3"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detected platform \"Colab\". Running its setup...\n",
            "Source files will be saved in \"/tmp/tmpzykvcgmq\".\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "\n",
        "// CUDA kernel for vector addition\n",
        "__global__ void vectorAdd(int* a, int* b, int* c, int size)\n",
        "{\n",
        "    int tid = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    if (tid < size) {\n",
        "        c[tid] = a[tid] + b[tid];\n",
        "    }\n",
        "}\n",
        "\n",
        "int main()\n",
        "{\n",
        "    int size = 100;  // Size of the vectors\n",
        "    int* a, * b, * c;    // Host vectors\n",
        "    int* dev_a, * dev_b, * dev_c;  // Device vectors\n",
        "\n",
        "    // Allocate memory for host vectors\n",
        "    a = (int*)malloc(size * sizeof(int));\n",
        "    b = (int*)malloc(size * sizeof(int));\n",
        "    c = (int*)malloc(size * sizeof(int));\n",
        "\n",
        "    // Initialize host vectors\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        a[i] = i;\n",
        "        b[i] = 2 * i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device for device vectors\n",
        "    cudaMalloc((void**)&dev_a, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, size * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, size * sizeof(int));\n",
        "\n",
        "    // Copy host vectors to device\n",
        "    cudaMemcpy(dev_a, a, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Launch kernel for vector addition\n",
        "    int blockSize = 256;\n",
        "    int gridSize = (size + blockSize - 1) / blockSize;\n",
        "    vectorAdd<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c, size);\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result\n",
        "    for (int i = 0; i < size; i++) {\n",
        "        printf(\"%d + %d = %d\\n\", a[i], b[i], c[i]);\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MX46RtHj4t3K",
        "outputId": "00ded904-c180-4bf5-838f-ab4b5897dd12"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 + 0 = 0\n",
            "1 + 2 = 3\n",
            "2 + 4 = 6\n",
            "3 + 6 = 9\n",
            "4 + 8 = 12\n",
            "5 + 10 = 15\n",
            "6 + 12 = 18\n",
            "7 + 14 = 21\n",
            "8 + 16 = 24\n",
            "9 + 18 = 27\n",
            "10 + 20 = 30\n",
            "11 + 22 = 33\n",
            "12 + 24 = 36\n",
            "13 + 26 = 39\n",
            "14 + 28 = 42\n",
            "15 + 30 = 45\n",
            "16 + 32 = 48\n",
            "17 + 34 = 51\n",
            "18 + 36 = 54\n",
            "19 + 38 = 57\n",
            "20 + 40 = 60\n",
            "21 + 42 = 63\n",
            "22 + 44 = 66\n",
            "23 + 46 = 69\n",
            "24 + 48 = 72\n",
            "25 + 50 = 75\n",
            "26 + 52 = 78\n",
            "27 + 54 = 81\n",
            "28 + 56 = 84\n",
            "29 + 58 = 87\n",
            "30 + 60 = 90\n",
            "31 + 62 = 93\n",
            "32 + 64 = 96\n",
            "33 + 66 = 99\n",
            "34 + 68 = 102\n",
            "35 + 70 = 105\n",
            "36 + 72 = 108\n",
            "37 + 74 = 111\n",
            "38 + 76 = 114\n",
            "39 + 78 = 117\n",
            "40 + 80 = 120\n",
            "41 + 82 = 123\n",
            "42 + 84 = 126\n",
            "43 + 86 = 129\n",
            "44 + 88 = 132\n",
            "45 + 90 = 135\n",
            "46 + 92 = 138\n",
            "47 + 94 = 141\n",
            "48 + 96 = 144\n",
            "49 + 98 = 147\n",
            "50 + 100 = 150\n",
            "51 + 102 = 153\n",
            "52 + 104 = 156\n",
            "53 + 106 = 159\n",
            "54 + 108 = 162\n",
            "55 + 110 = 165\n",
            "56 + 112 = 168\n",
            "57 + 114 = 171\n",
            "58 + 116 = 174\n",
            "59 + 118 = 177\n",
            "60 + 120 = 180\n",
            "61 + 122 = 183\n",
            "62 + 124 = 186\n",
            "63 + 126 = 189\n",
            "64 + 128 = 192\n",
            "65 + 130 = 195\n",
            "66 + 132 = 198\n",
            "67 + 134 = 201\n",
            "68 + 136 = 204\n",
            "69 + 138 = 207\n",
            "70 + 140 = 210\n",
            "71 + 142 = 213\n",
            "72 + 144 = 216\n",
            "73 + 146 = 219\n",
            "74 + 148 = 222\n",
            "75 + 150 = 225\n",
            "76 + 152 = 228\n",
            "77 + 154 = 231\n",
            "78 + 156 = 234\n",
            "79 + 158 = 237\n",
            "80 + 160 = 240\n",
            "81 + 162 = 243\n",
            "82 + 164 = 246\n",
            "83 + 166 = 249\n",
            "84 + 168 = 252\n",
            "85 + 170 = 255\n",
            "86 + 172 = 258\n",
            "87 + 174 = 261\n",
            "88 + 176 = 264\n",
            "89 + 178 = 267\n",
            "90 + 180 = 270\n",
            "91 + 182 = 273\n",
            "92 + 184 = 276\n",
            "93 + 186 = 279\n",
            "94 + 188 = 282\n",
            "95 + 190 = 285\n",
            "96 + 192 = 288\n",
            "97 + 194 = 291\n",
            "98 + 196 = 294\n",
            "99 + 198 = 297\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "%%cuda\n",
        "#include <stdio.h>\n",
        "#include <stdlib.h>\n",
        "#include <cuda_runtime.h>\n",
        "\n",
        "\n",
        "// CUDA kernel for matrix multiplication\n",
        "__global__ void matrixMul(int* a, int* b, int* c, int rowsA, int colsA, int colsB) {\n",
        "    int row = blockIdx.y * blockDim.y + threadIdx.y;\n",
        "    int col = blockIdx.x * blockDim.x + threadIdx.x;\n",
        "    int sum = 0;\n",
        "    if (row < rowsA && col < colsB) {\n",
        "        for (int i = 0; i < colsA; i++) {\n",
        "            sum += a[row * colsA + i] * b[i * colsB + col];\n",
        "        }\n",
        "        c[row * colsB + col] = sum;\n",
        "    }\n",
        "}\n",
        "\n",
        "int main() {\n",
        "    int rowsA = 10;  // Rows of matrix A\n",
        "    int colsA = 10;  // Columns of matrix A\n",
        "    int rowsB = colsA; // Rows of matrix B\n",
        "    int colsB = 10;  // Columns of matrix B\n",
        "\n",
        "    int* a, * b, * c;  // Host matrices\n",
        "    int* dev_a, * dev_b, * dev_c;  // Device matrices\n",
        "\n",
        "    // Allocate memory for host matrices\n",
        "    a = (int*)malloc(rowsA * colsA * sizeof(int));\n",
        "    b = (int*)malloc(rowsB * colsB * sizeof(int));\n",
        "    c = (int*)malloc(rowsA * colsB * sizeof(int));\n",
        "\n",
        "    // Initialize host matrices\n",
        "    for (int i = 0; i < rowsA * colsA; i++) {\n",
        "        a[i] = i;\n",
        "    }\n",
        "    for (int i = 0; i < rowsB * colsB; i++) {\n",
        "        b[i] = 2 * i;\n",
        "    }\n",
        "\n",
        "    // Allocate memory on the device for device matrices\n",
        "    cudaMalloc((void**)&dev_a, rowsA * colsA * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_b, rowsB * colsB * sizeof(int));\n",
        "    cudaMalloc((void**)&dev_c, rowsA * colsB * sizeof(int));\n",
        "\n",
        "    // Copy host matrices to device\n",
        "    cudaMemcpy(dev_a, a, rowsA * colsA * sizeof(int), cudaMemcpyHostToDevice);\n",
        "    cudaMemcpy(dev_b, b, rowsB * colsB * sizeof(int), cudaMemcpyHostToDevice);\n",
        "\n",
        "    // Define grid and block dimensions\n",
        "    dim3 blockSize(16, 16);\n",
        "    dim3 gridSize((colsB + blockSize.x - 1) / blockSize.x, (rowsA + blockSize.y - 1) / blockSize.y);\n",
        "\n",
        "    // Launch kernel for matrix multiplication\n",
        "    matrixMul<<<gridSize, blockSize>>>(dev_a, dev_b, dev_c, rowsA, colsA, colsB);\n",
        "\n",
        "    // Copy result from device to host\n",
        "    cudaMemcpy(c, dev_c, rowsA * colsB * sizeof(int), cudaMemcpyDeviceToHost);\n",
        "\n",
        "    // Print result\n",
        "    printf(\"Result:\\n\");\n",
        "    for (int i = 0; i < rowsA; i++) {\n",
        "        for (int j = 0; j < colsB; j++) {\n",
        "            printf(\"%d \", c[i * colsB + j]);\n",
        "        }\n",
        "        printf(\"\\n\");\n",
        "    }\n",
        "\n",
        "    // Free device memory\n",
        "    cudaFree(dev_a);\n",
        "    cudaFree(dev_b);\n",
        "    cudaFree(dev_c);\n",
        "\n",
        "    // Free host memory\n",
        "    free(a);\n",
        "    free(b);\n",
        "    free(c);\n",
        "\n",
        "    return 0;\n",
        "}\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n2p42Kku5Qnm",
        "outputId": "debb8f74-f1be-41f6-8247-3e022339b06f"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result:\n",
            "5700 5790 5880 5970 6060 6150 6240 6330 6420 6510 \n",
            "14700 14990 15280 15570 15860 16150 16440 16730 17020 17310 \n",
            "23700 24190 24680 25170 25660 26150 26640 27130 27620 28110 \n",
            "32700 33390 34080 34770 35460 36150 36840 37530 38220 38910 \n",
            "41700 42590 43480 44370 45260 46150 47040 47930 48820 49710 \n",
            "50700 51790 52880 53970 55060 56150 57240 58330 59420 60510 \n",
            "59700 60990 62280 63570 64860 66150 67440 68730 70020 71310 \n",
            "68700 70190 71680 73170 74660 76150 77640 79130 80620 82110 \n",
            "77700 79390 81080 82770 84460 86150 87840 89530 91220 92910 \n",
            "86700 88590 90480 92370 94260 96150 98040 99930 101820 103710 \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u4td6o-u7Ozk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}