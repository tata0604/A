package com.maddy;

import java.io.IOException;
import java.util.StringTokenizer;

import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.Mapper;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class WeatherData {
  
	public static class WeatherMapper extends Mapper<LongWritable, Text, Text, WeatherWritable> {

	    public void map(LongWritable key, Text value, Context context)
	            throws IOException, InterruptedException {

	        String line = value.toString();
	        StringTokenizer tokenizer = new StringTokenizer(line, ",");
	        String date = tokenizer.nextToken();
	        String time = tokenizer.nextToken();
	        float temperature = Float.parseFloat(tokenizer.nextToken());
	        float dewPoint = Float.parseFloat(tokenizer.nextToken());
	        float windSpeed = Float.parseFloat(tokenizer.nextToken());

	        context.write(new Text(date), new WeatherWritable(temperature, dewPoint, windSpeed));
	    }
	}


	public static class WeatherReducer extends Reducer<Text, WeatherWritable, Text, WeatherWritable> {

	    public void reduce(Text key, Iterable<WeatherWritable> values, Context context)
	            throws IOException, InterruptedException {

	        float sumTemperature = 0;
	        float sumDewPoint = 0;
	        float sumWindSpeed = 0;
	        int count = 0;

	        for (WeatherWritable value : values) {
	            sumTemperature += value.getTemperature();
	            sumDewPoint += value.getDewPoint();
	            sumWindSpeed += value.getWindSpeed();
	            count++;
	        }

	        float avgTemperature = sumTemperature / count;
	        float avgDewPoint = sumDewPoint / count;
	        float avgWindSpeed = sumWindSpeed / count;

	        context.write(key, new WeatherWritable(avgTemperature, avgDewPoint, avgWindSpeed));
	    }
	}


  public static void main(String[] args) throws Exception {
    Configuration conf = new Configuration();
    Job job = Job.getInstance(conf, "Weather Data");

    job.setJarByClass(WeatherData.class);
    job.setMapperClass(WeatherMapper.class);
    job.setReducerClass(WeatherReducer.class);

    job.setOutputKeyClass(Text.class);
    job.setOutputValueClass(WeatherWritable.class);

    FileInputFormat.addInputPath(job, new Path(args[0]));
    FileOutputFormat.setOutputPath(job, new Path(args[1]));

    System.exit(job.waitForCompletion(true) ? 0 : 1);
  }
}





package com.maddy;
import java.io.DataInput;
import java.io.DataOutput;
import java.io.IOException;
import org.apache.hadoop.io.Writable;

public class WeatherWritable implements Writable {

  private double temperature;
  private double dewPoint;
  private double windSpeed;

  public WeatherWritable() {}

  public WeatherWritable(double temperature, double dewPoint, double windSpeed) {
    this.temperature = temperature;
    this.dewPoint = dewPoint;
    this.windSpeed = windSpeed;
  }

  public void setTemperature(double temperature) {
    this.temperature = temperature;
  }

  public double getTemperature() {
    return temperature;
  }

  public void setDewPoint(double dewPoint) {
    this.dewPoint = dewPoint;
  }

  public double getDewPoint() {
    return dewPoint;
  }

  public void setWindSpeed(double windSpeed) {
    this.windSpeed = windSpeed;
  }

  public double getWindSpeed() {
    return windSpeed;
  }

  public void readFields(DataInput in) throws IOException {
    temperature = in.readDouble();
    dewPoint = in.readDouble();
    windSpeed = in.readDouble();
  }

  public void write(DataOutput out) throws IOException {
    out.writeDouble(temperature);
    out.writeDouble(dewPoint);
    out.writeDouble(windSpeed);
  }

  @Override
  public String toString() {
    return temperature + "\t" + dewPoint + "\t" + windSpeed;
  }
}



<dependencies>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-common</artifactId>
			<version>3.3.3</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hadoop</groupId>
			<artifactId>hadoop-mapreduce-client-core</artifactId>
			<version>3.3.3</version>
		</dependency>
	</dependencies>
